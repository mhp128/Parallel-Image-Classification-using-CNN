{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d4YnACkLMmcC",
        "OML3txbb2mDj",
        "14bNBn3mECQW",
        "OurWW4rgGXo5",
        "QCOTy97lN6HZ",
        "RYqhW7eQpfOg"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ĐỀ TÀI:  Image Classification using Convolution Neural Network**\n",
        "**Nhóm 8:**\n",
        "1. 19120620 - Mai Hồng Phúc\n",
        "2. 19120628 - Hoàng Anh Quân\n",
        "3. 19120633 - Nguyễn Anh Quốc\n",
        " \n",
        "### Keywords:\n",
        "CNN, parallel programming, image classification, CUDA, Deep learning\n",
        "\n",
        "### List of references:\n",
        "https://www.linkedin.com/pulse/forward-back-propagation-over-cnn-code-from-scratch-coy-ulloa/\n",
        "https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/\n",
        "https://arxiv.org/pdf/1511.08458.pdf\n",
        "https://jmyao17.github.io/Machine_Learning/Neural_Network/CNN-1/CNN_Build.html\n",
        "### Git repo project:\n",
        "https://github.com/mhp128/Parallel-Image-Classification-using-CNN\n",
        "## 1. Summary:\n",
        "Dự án của nhóm sẽ thực hiện song song hóa ứng dụng phân lớp hình ảnh sử dụng mạng Convolution Neural Network (CNN). Mạng CNN gồm nhiều lớp kết hợp lại với nhau: lớp convolution, lớp pooling, mạng dense,... Nhóm sẽ thực hiện song song hóa các bước thành phần và cả quá trình back propagation với hy vọng tốc độ thực thi của ứng dụng sẽ được tăng nhanh hơn so với phiên bản tuần tự của nó. Ứng dụng sẽ được thực hiện trên NVIDIA CUDA GPU.\n",
        "\n",
        "## 2. Background\n",
        "Trong những năm trở lại đây đã có sự nghiên cứu phát triển vượt bậc về việc sử dụng CNN cho các nhiệm vụ liên quan đến nhận dạng và phân loại hình ảnh. Ý tưởng chính của mô hình CNN là lấy hình ảnh làm đầu vào và rút trích các đặc trưng phức tạp hơn ở mỗi lớp ở độ phân giải thấp hơn. Sau các lớp rút trích này, có một vài lớp kích hoạt để đưa ra quyết định, dự đoán về hình ảnh.\n",
        "\n",
        "Việc đào tạo mô hình CNN cần một lượng lớn dữ liệu để hội tụ về cực tiểu toàn cục của chúng. Hệ quả là, việc đào tạo này rất nặng về tính toán và có thể mất nhiều giờ, thậm chí nhiều ngày để chạy trên các CPU truyền thống.\n",
        "\n",
        "Trong dự án này, nhóm mong muốn khai thác tính song song trong từng lớp của CNN như Pooling, FullyConnected, Convolution,..và sửa đổi thuật toán lan truyền ngược để phù hợp với kiến trúc CUDA và đạt được tốc độ cao.\n",
        "\n",
        "## 3. The challenge\n",
        "Việc đào tạo mạng nơ-ron tích chập (CNN) là một nhiệm vụ tính toán chuyên sâu nên yêu cầu đòi hỏi khả năng song song hóa hiệu quả để rút ngắn thời gian thực hiện.  Dữ liệu training cho mang nơ-ron ngày càng lớn nên việc song song hóa việc đào tạo mạng CNN trở nên quan trọng hơn. Các vấn đề, khó khăn gặp phải khi thực hiện song song hóa là:\n",
        "- Kết quả tính toán của mỗi lớp cần được chia sẻ giữa tất cả các thread vì tính toán của lớp tiếp theo phụ thuộc vào kết quả của lớp trước. Do đó, CNN có tỷ lệ giao tiếp để tính toán rất cao dẫn đến cường độ thực hiện song song trên GPU thấp\n",
        "- Giới hạn bộ nhớ: Số lượng mẫu đào tạo cho việc tính toán song song bị hạn chế đáng kể bởi vì bộ nhớ chung có sẵn cho GPU thấp.\n",
        "- Các lớp phụ thuộc vào nhau nên chỉ có sự song song trong một lớp chứ không phải giữa các lớp\n",
        "Để vượt qua những thử thách kể trên, yêu cầu nhóm tối ưu hóa kiến trúc CNN để sử dụng ít bộ nhớ hơn và ít yêu cầu giao tiếp hơn, sử dụng lại bộ nhớ để không phải tải nhiều lần từ CPU sang GPU.\n",
        "\n",
        "## 4. Resources\n",
        "Đối với đề tài này nhóm sử dụng máy chủ Colab (Tên CPU: Persitence M, 13GB Ram, Tên GPU: Tesla T4) để tiến hành cài đặt chương trình tuần tự và song song cho việc huấn luyện mô hình CNN. Mã nguồn cài đặt mô hình CNN sẽ xây dựng từ đầu, có thể sử dụng một số thư viện hỗ trợ như numpy, thư viện được sử dụng để cài đặt song song là Numba. Bài báo mô tả về mô hình CNN: https://arxiv.org/pdf/1511.08458.pdf. Các tài nguyên về dữ liệu huấn luyện phân loại ảnh đều đã có sẵn trên các thư viện của tensorflow như MNIST, CIFAR-10,...\n",
        "\n",
        "## 5. Goals And Deliverables\n",
        "- Trong dự án này, nhóm sẽ thực hiện song song hóa mạng CNN bắt đầu từ phiên bản tuần tự. Mục tiêu mà nhóm đặt ra là xây dựng được phiên bản song song với tốc độ thực thi tương đương (hoặc chậm hơn không quá nhiều) so với mô hình được xây dựng từ các thư viện chuẩn (keras, tensorflow, pytorch,...) vì đây là các framework được tối ưu về tốc độ thực thi. Hoặc ít nhất là ứng dụng được tạo ra chạy nhanh hơn so với phiên bản tuần tự. Nếu tiến độ của dự án nhanh hơn và tốt hơn, nhóm có thể sẽ tối ưu ứng dụng về dung lượng bộ nhớ, hoặc song song hóa các lớp thành phần trên tập dữ liệu 3D.\n",
        "- Nhóm sẽ demo ứng dụng song song của mình đang hoạt động và so sánh thời gian chạy trên các tập dữ liệu khác nhau. Nhóm cũng sẽ trình bày các biểu đồ tốc độ thực thi so sánh các phiên bản tuần tự và song song của mạng CNN cũng như mô tả một số cách tối ưu hóa mà nhóm đã sử dụng.\n",
        "- Các câu hỏi mà nhóm cần trả lời trong phân tích dự án: Để thực hiện dự án thì cần làm những công việc gì và cần thời gian bao lâu? Công việc của mỗi thành viên được phân chia như thế nào? Thời gian thực hiện cho từng công việc là bao lâu? Nếu có một thành viên chưa hoàn thành xong công việc trước thời hạn thì nên giải quyết thế nào? Những rủi ro nào có thể xảy ra trong quá trình thực hiện dự án? Liệu dự án có cho ra được kết quả như ý muốn? Việc tối ưu thời gian của ứng dụng có phải là điều cần thiết? Lợi ích lớn nhất của dự án là gì?\n",
        "- Ứng dụng có thể song song các tác vụ độc lập như phép tích chập, nhân ma trận, tính toán trên từng batch,... Hiệu suất của phiên bản song song mà nhóm hy vọng đạt được có thể nhanh gấp khoảng 10-30 lần so với việc cài đặt tuần tự.\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://codetolight.files.wordpress.com/2017/11/network.png?w=1108\"\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "d4YnACkLMmcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Build CNN model\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "import time\n",
        "# from CNNModel import CNNModel\n",
        "# from layers import Convolution, Flatten, MaxPool2D, Dense\n",
        "class Layer():\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        pass\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        pass\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        pass\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass\n",
        "# from layers_v1 import Layer\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "class CNNModel:\n",
        "    def __init__(self, layers: list[Layer] = []):\n",
        "        pre_layer = layers[0]\n",
        "        pre_layer.init_weight()\n",
        "        for layer in layers[1:]:\n",
        "            layer.input_shape = pre_layer.get_out_shape()\n",
        "            layer.init_weight()\n",
        "            pre_layer = layer\n",
        "        self.layers: list[Layer] = layers\n",
        "\n",
        "    def forward(self, X):\n",
        "        output = X\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward(output)\n",
        "        return output\n",
        "\n",
        "    def backward(self, out_grad, learning_rate):\n",
        "        for layer in reversed(self.layers):\n",
        "            out_grad = layer.backward(out_grad, learning_rate)\n",
        "        return out_grad\n",
        "\n",
        "    def fit(self, X_train, Y_train, epochs=1, batch_size=32, learning_rate=0.001):\n",
        "        num_batch = (len(X_train)-1)//batch_size+1\n",
        "        for i_epoch in range(epochs):\n",
        "            print(f\"\\nEpoch {i_epoch+1}/{epochs}:\")\n",
        "            train_loss = 0\n",
        "            acc = 0\n",
        "            progress = '.'*30\n",
        "            for i in range(num_batch-1):\n",
        "\n",
        "                batch_start = i * batch_size\n",
        "                batch_end = (i + 1) * batch_size\n",
        "                batch_X = X_train[batch_start: batch_end]\n",
        "                batch_Y = Y_train[batch_start: batch_end]\n",
        "                predictions = self.forward(batch_X)\n",
        "                out_grad = 2.0 * (predictions - batch_Y)\n",
        "                self.backward(out_grad, learning_rate)\n",
        "\n",
        "                # print result\n",
        "                acc_batch = np.mean(\n",
        "                    np.argmax(predictions, axis=1) == np.argmax(batch_Y, axis=1))\n",
        "                acc += acc_batch\n",
        "                loss = np.sum((predictions - batch_Y) ** 2)\n",
        "                train_loss += loss\n",
        "                i_str = int(i/num_batch*30)\n",
        "                progress = progress[:i_str] + \">\" + progress[i_str+1:]\n",
        "                print(\n",
        "                    f\"\\r {i}/{num_batch} [{progress}] accuaray: {acc_batch:.5f}, train loss = {loss/len(batch_Y):.5f}\", end='')\n",
        "                progress = progress[:i_str] + \"=\" + progress[i_str+1:]\n",
        "\n",
        "            train_loss /= len(X_train)\n",
        "\n",
        "            print(\n",
        "                f\"\\r {num_batch}/{num_batch} [{progress}] accuaray: {acc/num_batch:.5f}, train loss = {train_loss:.5f}\", end='')\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.forward(X)\n",
        "\n",
        "    def use_device(self, value):\n",
        "        for layer in self.layers:\n",
        "            output = layer.use_device = value\n",
        "\n",
        "\n",
        "class Flatten(Layer):\n",
        "    def __init__(self, input_shape=(28, 28, 1)):\n",
        "        self.input_shape = input_shape\n",
        "        pass\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        t = 1\n",
        "        for i in self.input_shape:\n",
        "            t *= i\n",
        "        return t\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        return inputs.reshape(inputs.shape[0], -1)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        shape = self.inputs.shape\n",
        "        return output_gradient.reshape(shape)\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "Eazr70Pw36Gj",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Mnist Dataset\n",
        "\n",
        "from keras.datasets import mnist\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "y_train = np.zeros((len(train_y),10))\n",
        "y_test = np.zeros((len(test_y),10))\n",
        "for i in range (len(y_train)):\n",
        "  y_train[i,train_y[i]]=1\n",
        "for i in range (len(y_test)):\n",
        "  y_test[i,test_y[i]]=1\n",
        "x_train=train_X.reshape(train_X.shape[0],1, train_X.shape[1], train_X.shape[2])\n",
        "x_test=test_X.reshape(test_X.shape[0],1, test_X.shape[1], test_X.shape[2])\n",
        "x_train=x_train/255\n",
        "x_test=x_test/255"
      ],
      "metadata": {
        "id": "xqbkRDXWJ6Gd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "8895f5df-b584-4379-c6c3-7c91c9d672b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. PHIÊN BẢN TUẦN TỰ V1"
      ],
      "metadata": {
        "id": "OML3txbb2mDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân tích:\n",
        "```\n",
        "Để cài đặt một mô hình CNN chúng ta cần thực hiện 2 công việc chính:\n",
        "- Forward (Lan truyền tiến): Tính toán kết quả một cách tuần tự từ lớp đầu tiên đến lớp cuối cùng\n",
        "- Backward (Lan truyền ngược): Là bước cập nhật trọng số của mô hình, việc tính toán sẽ bắt đầu từ lớp cuối về lớp đầu tiên.\n",
        "Cài đặt thuật toán CNN cơ bản gồm 3 lớp chính là Convolution, Maxpooling, Dense. Với 2 bước chính gồm forward và backward.\n",
        "```"
      ],
      "metadata": {
        "id": "HBYjBEhS52t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convolution Layer\n",
        "\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "import time\n",
        "\n",
        "#------------Convolution kernel--------------#\n",
        "class Convolution(Layer):\n",
        "    def __init__(self, n_filters=32, filter_size=3, stride=1, activation=None, input_shape=(28, 28, 1)):\n",
        "        self.input_shape = input_shape\n",
        "        self.n_filters = n_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.bias = np.zeros((n_filters, 1))\n",
        "        self.init_weight()\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_width = (self.input_shape[2] -\n",
        "                        self.filter_size) // self.stride + 1\n",
        "        output_height = (\n",
        "            self.input_shape[1] - self.filter_size) // self.stride + 1\n",
        "\n",
        "        return ( self.n_filters,output_height, output_width)\n",
        "    def init_weight(self):\n",
        "        self.weights = np.random.randn(\n",
        "            self.n_filters, self.input_shape[0],self.filter_size, self.filter_size)/(self.filter_size**2)\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        n_batchs, n_chanels,in_height, in_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        output_height, output_width = self.get_out_shape()[1:]\n",
        "        ## ===========USING CPU===========##\n",
        "        outputs = np.zeros( (n_batchs, self.n_filters,output_height, output_width ))\n",
        "        for i_idx in range(n_batchs):\n",
        "            for row in range(output_height):\n",
        "                for col in range(output_width):\n",
        "                    for f_idx in range(self.n_filters):\n",
        "                        row_start = row * self.stride\n",
        "                        row_end = row_start + self.filter_size\n",
        "                        col_start = col * self.stride\n",
        "                        col_end = col_start + self.filter_size\n",
        "                        outputs[i_idx,f_idx, row, col] = np.sum(\n",
        "                            self.weights[f_idx] * inputs[i_idx, :, row_start:row_end, col_start:col_end])\n",
        "\n",
        "        if(self.activation == \"relu\"):\n",
        "            outputs = np.maximum(0, outputs)\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        n_batchs,input_channels, input_height, input_width = self.inputs.shape\n",
        "        _,n_filters,  output_height, output_width = output_gradient.shape\n",
        "        ## ===========USING CPU===========##\n",
        "        filter_gradient = np.zeros(self.weights.shape)\n",
        "        input_gradient = np.zeros(self.inputs.shape)\n",
        "        for i_batch in range(n_batchs):\n",
        "            for row in range(output_height):\n",
        "                for col in range(output_width):\n",
        "                    for fillterIdx in range(n_filters):\n",
        "                        row_start = row * self.stride\n",
        "                        row_end = row_start + self.filter_size\n",
        "                        col_start = col * self.stride\n",
        "                        col_end = col_start + self.filter_size\n",
        "                        out_grad_val = output_gradient[i_batch,fillterIdx, row, col ]\n",
        "                        filter_gradient[fillterIdx] += self.inputs[i_batch, :,row_start:row_end, col_start:col_end] * out_grad_val\n",
        "                        input_gradient[i_batch, :, row_start:row_end, col_start:col_end] += self.weights[fillterIdx] * out_grad_val\n",
        "        if(self.activation == \"relu\"):\n",
        "            input_gradient[self.inputs <= 0] = 0\n",
        "\n",
        "        self.weights -= learning_rate * filter_gradient/n_batchs\n",
        "\n",
        "        return filter_gradient\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YsgSm0vy8jhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Convolution\n",
        "```\n",
        "+ Forward:\n",
        "  Input: Tập ảnh đầu vào, số lượng filter, kích thước filter, stride,   hàm kích hoạt\n",
        "  Các bước thực hiện:\n",
        "    Cấp phát bộ nhớ cho tập ảnh đầu ra\n",
        "    Tạo ngẫu nhiên trọng số cho các filter\n",
        "    Thực hiện convolution cho từng pixel theo số lượng filter bằng cách sử dụng các vòng lặp lồng nhau\n",
        "    Áp dụng hàm kích hoạt cho kết quả vừa tạo ra\n",
        "  Output: Tập ảnh kết quả\n",
        "\n",
        "+Backward:\n",
        "  Input: Output gradient, learning rate\n",
        "  Các bước thực hiện:\n",
        "    Cấp phát bộ nhớ cho input gradient và filter gradient\n",
        "    Tính toán input gradient và filter gradient\n",
        "    Cập nhật trọng số cho filter: filter = filter - learning rate * filter gradient\n",
        "  Output: Input gradient\n",
        "```"
      ],
      "metadata": {
        "id": "xrz6JcKWkGh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "VGjesCaT9weD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(16,100,100)\n",
        "inputs = np.random.randint(0,255,(32,*input_shape))/255\n",
        "conv = Convolution(32,3,1,input_shape=input_shape)\n",
        "%time out_host=conv.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cM5dLtS9B3e",
        "outputId": "fc17e4f2-2498-4203-d75c-de1240b1ae84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 16s, sys: 226 ms, total: 1min 16s\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "ZFSp7B2J9zmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=conv.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXdEL199s_l",
        "outputId": "4051e98b-064a-4b55-fea1-b60d66510287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 22s, sys: 375 ms, total: 2min 22s\n",
            "Wall time: 2min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Convolution\n",
        "```\n",
        "+ Forward:\n",
        "  Input: Tập ảnh đầu vào, số lượng filter, kích thước filter, stride,   hàm kích hoạt\n",
        "  Các bước thực hiện:\n",
        "    Cấp phát bộ nhớ cho tập ảnh đầu ra\n",
        "    Tạo ngẫu nhiên trọng số cho các filter\n",
        "    Thực hiện convolution cho từng pixel theo số lượng filter bằng cách sử dụng các vòng lặp lồng nhau\n",
        "    Áp dụng hàm kích hoạt cho kết quả vừa tạo ra\n",
        "  Output: Tập ảnh kết quả\n",
        "\n",
        "+Backward:\n",
        "  Input: Output gradient, learning rate\n",
        "  Các bước thực hiện:\n",
        "    Cấp phát bộ nhớ cho input gradient và filter gradient\n",
        "    Tính toán input gradient và filter gradient\n",
        "    Cập nhật trọng số cho filter: filter = filter - learning rate * filter gradient\n",
        "  Output: Input gradient\n",
        "```"
      ],
      "metadata": {
        "id": "c-OExWK8jjx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Maxpooling Layer\n",
        "class MaxPool2D(Layer):\n",
        "    def __init__(self, pool_size=2, stride=2, input_shape=(28, 28, 1)):\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.inputs_device = None\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_height = ( self.input_shape[1] - self.pool_size) // self.stride + 1\n",
        "        output_width = (self.input_shape[2] -  self.pool_size) // self.stride + 1\n",
        "        return (self.input_shape[0],output_height, output_width)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # Save input\n",
        "        batch_size,num_channels, input_height, input_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        self.inputs = inputs\n",
        "        ( _,output_height, output_width) = self.get_out_shape()\n",
        "        outputs = np.zeros( (batch_size,num_channels, output_height, output_width))\n",
        "        for c in range(num_channels):\n",
        "            for h in range(output_height):\n",
        "                for w in range(output_width):\n",
        "                    h_start = h * self.stride\n",
        "                    h_end = h_start + self.pool_size\n",
        "                    w_start = w * self.stride\n",
        "                    w_end = w_start + self.pool_size\n",
        "                    outputs[:,c, h, w] = np.max( inputs[:,c, h_start:h_end, w_start:w_end], axis=(1, 2))\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        batch_size,num_channels, output_height, output_width = output_gradient.shape\n",
        "        input_gradient = np.zeros(self.inputs.shape)\n",
        "        for c in range(num_channels):\n",
        "            for h in range(output_height):\n",
        "                for w in range(output_width):\n",
        "                    h_start = h * self.stride\n",
        "                    h_end = h_start + self.pool_size\n",
        "                    w_start = w * self.stride\n",
        "                    w_end = w_start + self.pool_size\n",
        "                    input_slice = self.inputs[:,c,h_start:h_end, w_start:w_end]\n",
        "                    max_vals = np.max( input_slice, axis=(1, 2), keepdims=True)\n",
        "                    max_mask = (input_slice == max_vals)\n",
        "                    input_gradient[:, c,h_start:h_end, w_start:w_end] += max_mask * \\\n",
        "                        output_gradient[:, c, h, w, np.newaxis, np.newaxis]\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f7W29ATx2398"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Maxpooling\n",
        "```\n",
        "+ Forward:\n",
        "Input: Ma trận đầu vào, kích thước pool, stride\n",
        "Các bước thực hiện:\n",
        "  Tính kích thước ma trận kết quả\n",
        "  Ứng với mỗi cột và dòng của ma trận kết quả  lấy số lớn nhất trong từng vùng của ma trận đầu vào ứng với kích thước pool sau dịch chuyển vùng này sang một khoảng stride và tiếp tục cho đến hết\n",
        "Output: Ma trận kết quả\n",
        "\n",
        "+Backward:\n",
        "Input: Output gradient, learning rate\n",
        "Các bước thực hiện:\n",
        "  Cấp phát bộ nhớ cho input gradient\n",
        "  Xác định vị trí pixel lớn nhất được chọn\n",
        "  Tính toán input gradient\n",
        "Output: Input gradient\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "wLkFPYWCkQ4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "o-SZh3oLAsHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(32,200,200)\n",
        "inputs = np.random.randint(0,255,(64,*input_shape))/255\n",
        "maxp = MaxPool2D(2,2,input_shape=input_shape)\n",
        "%time out_host=maxp.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yffA5rm6_CCs",
        "outputId": "4c8d9f1c-b12a-4049-9c51-487db94574ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.75 s, sys: 228 ms, total: 3.98 s\n",
            "Wall time: 3.88 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "6eVppwiZAso7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=maxp.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vt-_uIU_UG8",
        "outputId": "d510b72b-bdad-4936-c919-145241e11305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.4 s, sys: 1.48 s, total: 14.8 s\n",
            "Wall time: 15.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Dense Layer\n",
        "class Dense(Layer):\n",
        "    def __init__(self, num_outputs, activation=None, input_shape=100):\n",
        "        self.num_outputs = num_outputs\n",
        "        self.biases = np.zeros((1, num_outputs))\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.input_shape = input_shape\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        self.weights = np.random.randn(\n",
        "            self.input_shape, self.num_outputs) / self.num_outputs\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        return self.num_outputs\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        assert self.input_shape == inputs.shape[-1], \"Input shape incorrect\"\n",
        "        outputs = np.dot(inputs, self.weights) + self.biases\n",
        "        if self.activation == \"softmax\":\n",
        "            outputs = self.softmax(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x-np.max(x, axis=1, keepdims=True))\n",
        "        return e_x/e_x.sum(axis=1, keepdims=True)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        input_grad = np.dot(output_gradient, self.weights.T)\n",
        "        weights_gradient = np.dot(self.inputs.T, output_gradient)\n",
        "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.biases -= learning_rate * biases_gradient\n",
        "        return input_grad\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KGK25vv586Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Dense\n",
        "```\n",
        "+Forward:\n",
        "Input: Ma trận đầu vào, số lượng output mong muốn, hàm kích hoạt\n",
        "Các bước thực hiện:\n",
        "  Khởi tạo ngẫu nhiên ma trận trọng số\n",
        "  Thực hiện nhân ma trận đầu vào với ma trận trọng số cộng với ma trận bias tạo ra ma trận kết quả\n",
        "  Nếu hàm kích hoạt là softmax thì kết quả sẽ ra ma trận xác suất của các lớp\n",
        "Output: Ma trận kết quả\n",
        "\n",
        "+Backward:\n",
        "Input: Output gradient, Learning rate\n",
        "Các bước thực hiện:\n",
        "  Nhân ma trận output gradient với nghịch đảo của ma trận trong số tạo ra ma trận input gradient\n",
        "  Cập nhật ma trận trọng số:\n",
        "  weights = weights - (learning rate * weights gradient)\n",
        "  Trong đó weights gradient = nghịch đảo của ma trận đầu vào của lớp trước đó nhân với output gradient\n",
        "  Cập nhật chỉ số bias:\n",
        "  bias = bias - (learning rate * bias gradient)\n",
        "Trong đó bias gradient = tổng của tất các cột của output gradient\n",
        "Output: Input grad\n",
        "```"
      ],
      "metadata": {
        "id": "fcCprViekgWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "wfOQ0OkbrCdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=np.random.randint(1,255, (256,10000))/255\n",
        "dense=Dense(1024, input_shape= 10000)\n",
        "%time out_host=dense.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDJ176Qk_DAy",
        "outputId": "ac733484-20a9-4aa7-a2b9-ad9372e2786a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 292 ms, sys: 3.99 ms, total: 296 ms\n",
            "Wall time: 150 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test"
      ],
      "metadata": {
        "id": "5v17vSsjaEEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelI=CNNModel([ \n",
        "    Convolution(n_filters=16, filter_size=3, stride=1,activation='relu',input_shape=(1,28,28)),\n",
        "    MaxPool2D(pool_size=2), \n",
        "    Convolution(n_filters=32, filter_size=3, stride=1,activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "R1DstFSpaEEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "modelI.fit(x_train,y_train, epochs=3, batch_size=128)\n",
        "# Thời gian chạy quá lâu nên không thể đo được."
      ],
      "metadata": {
        "id": "b-uRJrfLaEEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time y_predict =modelI.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4ecec8-81b6-4969-9774-9dc94f553a24",
        "id": "vg0dR-m-aEEy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17min 19s, sys: 3.06 s, total: 17min 22s\n",
            "Wall time: 17min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. PHIÊN BẢN TUẦN TỰ V2"
      ],
      "metadata": {
        "id": "14bNBn3mECQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân tích:\n",
        "```\n",
        "- Việc sử sử dụng vòng lặp trong python rất chậm cho việc tính toán với độ phức tạp lớn.\n",
        "- Phiên bản tuần tự 2 cải tiến việc sử dụng numpy thay cho vòng lặp để tính toán với tốc độ nhanh hơn.\n",
        "- Các bước thiết kế các lớp Conv, pool, Dense tương tự như phiên bản tuần tự v1\n",
        "```"
      ],
      "metadata": {
        "id": "rSw40TIKECQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convolution Layer\n",
        "class Convolution(Layer):\n",
        "    def __init__(self, n_filters=32, filter_size=3, stride=1, activation=None, input_shape=(1, 28, 28)):\n",
        "        self.input_shape = input_shape\n",
        "        self.n_filters = n_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.bias = np.zeros((n_filters, 1))\n",
        "        self.init_weight()\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_width = (self.input_shape[2] -\n",
        "                        self.filter_size) // self.stride + 1\n",
        "        output_height = (\n",
        "            self.input_shape[1] - self.filter_size) // self.stride + 1\n",
        "\n",
        "        return ( self.n_filters,output_height, output_width)\n",
        "\n",
        "    def init_weight(self):\n",
        "        np.random.seed(10)\n",
        "        self.weights = np.random.randn(\n",
        "            self.n_filters, self.input_shape[0],self.filter_size, self.filter_size)/(self.filter_size**2)\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        n_batchs, n_chanels,in_height, in_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        output_height, output_width = self.get_out_shape()[1:]\n",
        "        outputs = np.zeros( (n_batchs, self.n_filters,output_height, output_width ))\n",
        "        for row in range(output_height):\n",
        "            for col in range(output_width):\n",
        "                for f_idx in range(self.n_filters):\n",
        "                    row_start = row * self.stride\n",
        "                    row_end = row_start + self.filter_size\n",
        "                    col_start = col * self.stride\n",
        "                    col_end = col_start + self.filter_size\n",
        "                    outputs[:,f_idx, row, col ] = np.sum(\n",
        "                        self.weights[f_idx]*inputs[:, :, row_start:row_end, col_start:col_end],axis=(1,2,3) )\n",
        "\n",
        "        if(self.activation == \"relu\"):\n",
        "            outputs = np.maximum(0, outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        n_batchs,input_channels, input_height, input_width = self.inputs.shape\n",
        "        _,n_filters,  output_height, output_width = output_gradient.shape\n",
        "\n",
        "        filter_gradient = np.zeros(self.weights.shape)\n",
        "        input_gradient = np.zeros(self.inputs.shape)\n",
        "        # for i_batch in range(n_batchs):\n",
        "        for row in range(output_height):\n",
        "            for col in range(output_width):\n",
        "                for fillterIdx in range(n_filters):\n",
        "                    row_start = row * self.stride\n",
        "                    row_end = row_start + self.filter_size\n",
        "                    col_start = col * self.stride\n",
        "                    col_end = col_start + self.filter_size\n",
        "                    out_grad_val = output_gradient[:,fillterIdx, row, col,np.newaxis,np.newaxis,np.newaxis]\n",
        "                    filter_gradient[fillterIdx] +=  np.sum(self.inputs[:, :, row_start:row_end, col_start:col_end] * out_grad_val,axis=0)\n",
        "                    input_gradient[:,: , row_start:row_end, col_start:col_end] += self.weights[fillterIdx] * out_grad_val\n",
        "\n",
        "        if(self.activation == \"relu\"):\n",
        "              input_gradient[self.inputs <= 0] = 0\n",
        "\n",
        "        self.weights -= learning_rate * filter_gradient/n_batchs\n",
        "        return input_gradient\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jXRdy2YXECQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "vK-haEBRECQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(16,100,100)\n",
        "inputs = np.random.randint(0,255,(32,*input_shape))/255\n",
        "conv = Convolution(32,3,1,input_shape=input_shape)\n",
        "%time out_host=conv.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6c20df-88df-4f59-bec3-5ccffb988bc2",
        "id": "tMblREnRECQp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.3 s, sys: 81.7 ms, total: 11.4 s\n",
            "Wall time: 11.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "hG33_MBsECQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=conv.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7be2b2b-bcd1-4067-ce6b-550daac9d34e",
        "id": "KrJ9pEjvECQq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25.6 s, sys: 97.9 ms, total: 25.7 s\n",
            "Wall time: 25.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Maxpooling Layer\n",
        "\n",
        "class MaxPool2D(Layer):\n",
        "    def __init__(self, pool_size=2, stride=2, input_shape=(1,28, 28)):\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.inputs_device = None\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_height = ( self.input_shape[1] - self.pool_size) // self.stride + 1\n",
        "        output_width = (self.input_shape[2] -  self.pool_size) // self.stride + 1\n",
        "        return (self.input_shape[0],output_height, output_width)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Save input\n",
        "        batch_size,num_channels, input_height, input_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        self.inputs = inputs\n",
        "        ( _,output_height, output_width) = self.get_out_shape()\n",
        "\n",
        "        outputs = np.zeros( (batch_size,num_channels, output_height, output_width))\n",
        "        for h in range(output_height):\n",
        "            for w in range(output_width):\n",
        "                h_start = h * self.stride\n",
        "                h_end = h_start + self.pool_size\n",
        "                w_start = w * self.stride\n",
        "                w_end = w_start + self.pool_size\n",
        "                outputs[:, :,h, w] = np.max( inputs[:, :, h_start:h_end, w_start:w_end], axis=(2, 3))\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        batch_size,num_channels, output_height, output_width = output_gradient.shape\n",
        "        input_gradient = np.zeros(self.inputs.shape)\n",
        "        for h in range(output_height):\n",
        "            for w in range(output_width):\n",
        "                h_start = h * self.stride\n",
        "                h_end = h_start + self.pool_size\n",
        "                w_start = w * self.stride\n",
        "                w_end = w_start + self.pool_size\n",
        "                input_slice = self.inputs[:, :, h_start:h_end, w_start:w_end]\n",
        "                max_vals = np.max(\n",
        "                    input_slice, axis=(2, 3), keepdims=True)\n",
        "                max_mask = (input_slice == max_vals)\n",
        "                input_gradient[:,:, h_start:h_end, w_start:w_end] += max_mask * output_gradient[:,:,  h, w,  np.newaxis, np.newaxis]\n",
        "        return input_gradient\n",
        "    def init_weight(self):\n",
        "        pass\n",
        "\n"
      ],
      "metadata": {
        "id": "KhdobMK-ECQq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "tjxkj1gzECQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(32,200,200)\n",
        "inputs = np.random.randint(0,255,(64,*input_shape))/255\n",
        "maxp = MaxPool2D(2,2,input_shape=input_shape)\n",
        "%time out_host=maxp.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa38651a-8095-468b-faa8-788b69068a06",
        "id": "wb1vxNtzECQr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.86 s, sys: 81.9 ms, total: 2.94 s\n",
            "Wall time: 2.98 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "Md_jUll8ECQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=maxp.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96ed226-f4a1-492e-c06c-9f2916cf386d",
        "id": "7T4IzxbHECQr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.76 s, sys: 497 ms, total: 6.25 s\n",
            "Wall time: 6.23 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Dense Layer\n",
        "class Dense(Layer):\n",
        "    def __init__(self, num_outputs, activation=None, input_shape=100):\n",
        "        self.num_outputs = num_outputs\n",
        "        self.biases = np.zeros((1, num_outputs))\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.input_shape = input_shape\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        self.weights = np.random.randn(\n",
        "            self.input_shape, self.num_outputs) / self.num_outputs\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        return self.num_outputs\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        assert self.input_shape == inputs.shape[-1], \"Input shape incorrect\"\n",
        "        outputs = np.dot(inputs, self.weights) + self.biases\n",
        "        if self.activation == \"softmax\":\n",
        "            outputs = self.softmax(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x-np.max(x, axis=1, keepdims=True))\n",
        "        return e_x/e_x.sum(axis=1, keepdims=True)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        input_grad = np.dot(output_gradient, self.weights.T)\n",
        "        weights_gradient = np.dot(self.inputs.T, output_gradient)\n",
        "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.biases -= learning_rate * biases_gradient\n",
        "        return input_grad\n",
        "\n",
        "\n",
        "class Flatten(Layer):\n",
        "    def __init__(self, input_shape=(28, 28, 1)):\n",
        "        self.input_shape = input_shape\n",
        "        pass\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        t = 1\n",
        "        for i in self.input_shape:\n",
        "            t *= i\n",
        "        return t\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        return inputs.reshape(inputs.shape[0], -1)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        shape = self.inputs.shape\n",
        "        return output_gradient.reshape(shape)\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "8jaVxtnjECQs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=np.random.randint(1,255, (256,10000))/255\n",
        "dense=Dense(1024, input_shape= 10000)\n",
        "%time out_host=dense.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863182bf-388b-41f9-f1f2-248ff9b5f9dd",
        "id": "1PLmeHk7ECQs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 289 ms, sys: 13 µs, total: 289 ms\n",
            "Wall time: 145 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test"
      ],
      "metadata": {
        "id": "NC2IJg3iKtLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelII=CNNModel([ \n",
        "    Convolution(n_filters=16, filter_size=3, stride=1,activation='relu',input_shape=(1,28,28)),\n",
        "    MaxPool2D(pool_size=2), \n",
        "    Convolution(n_filters=32, filter_size=3, stride=1,activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "qiiItW8MKhE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "modelII.fit(x_train,y_train, epochs=3, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2GUEMtoKzM8",
        "outputId": "4ce6e6ea-ff90-4018-f26d-2f6f67e1508f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3:\n",
            " 469/469 [==============================] accuaray: 0.89899, train loss = 0.16171\n",
            "Epoch 2/3:\n",
            " 469/469 [==============================] accuaray: 0.95198, train loss = 0.07217\n",
            "Epoch 3/3:\n",
            " 469/469 [==============================] accuaray: 0.96643, train loss = 0.05036CPU times: user 1h 1min 10s, sys: 2min 13s, total: 1h 3min 24s\n",
            "Wall time: 1h 4min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time y_predict =modelII.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSPkbgIyVqml",
        "outputId": "3b48ce1e-aa1e-418b-ca94-df689bc2b63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 30s, sys: 962 ms, total: 1min 31s\n",
            "Wall time: 1min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. PHIÊN BẢN SONG SONG V1"
      ],
      "metadata": {
        "id": "OurWW4rgGXo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân tích:\n",
        "```\n",
        "Phiên bản song song đầu tiên chỉ đơn thuần là ánh xạ phiên bản tuần tự bằng cách sử dụng grid và thread thay thế các vòng lặp\n",
        "Chưa sử dụng các kỹ thuật tối ưu như stream, sử dụng SMEM, giảm wap phân kỳ, chọn block size,...\n",
        "\n",
        "Giữa các lớp có sự liên kết với nhau (output của lớp này là input lớp kế tiếp) nên ta không thể song song việc tính toán của các lớp cùng một lúc mà phải tách nhỏ các công việc để song song\n",
        "\n",
        "Công việc tính toán tốn nhiều thời gian chủ yếu rơi vào việc tính forward và backward, nên ta chỉ cần song song hóa những hàm này trên từng lớp\n",
        "```"
      ],
      "metadata": {
        "id": "mTOtAqlFGXpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convolution Layer\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "\n",
        "#------------Convolution kernel--------------#\n",
        "@cuda.jit\n",
        "def conv_forward_kernel(inputs, weights, stride, outputs, activation):\n",
        "    n_chanels=inputs.shape[1]\n",
        "    filter_size= weights.shape[-1]\n",
        "    n_batch, n_filters,output_height, output_width = outputs.shape\n",
        "    i_batch, row, col = cuda.grid(3)\n",
        "    if(row >= output_height or col >= output_width or i_batch >= n_batch):\n",
        "        return\n",
        "\n",
        "    for fillterIdx in range(n_filters):\n",
        "        sum = 0\n",
        "        for chanel_idx in range(n_chanels):\n",
        "            for fillterRow in range(filter_size):\n",
        "                for fillterCol in range(filter_size):\n",
        "                    iR = row*stride + fillterRow\n",
        "                    iC = col*stride + fillterCol\n",
        "                    sum += inputs[i_batch,chanel_idx, iR, iC] * weights[fillterIdx,chanel_idx, fillterRow, fillterCol]\n",
        "        if(activation == 1 and sum < 0):\n",
        "            sum = 0\n",
        "        outputs[i_batch,fillterIdx, row, col] = sum\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def conv_backward_kernel(input, weights, stride, input_gradient, output_gradient, filter_gradient, activation):\n",
        "    n_chanels,filter_size = weights.shape[1:-1]\n",
        "    n_batch,n_filters, output_height, output_width  = output_gradient.shape\n",
        "    i_batch, row, col = cuda.grid(3)\n",
        "    if(row >= output_height or col >= output_width or i_batch >= n_batch):\n",
        "        return\n",
        "\n",
        "    for fillterIdx in range(n_filters):\n",
        "        for fillterRow in range(filter_size):\n",
        "            for fillterCol in range(filter_size):\n",
        "                out_value = output_gradient[i_batch, fillterIdx,row, col]\n",
        "                for i_chanel in range(n_chanels):\n",
        "                    iR = row*stride + fillterRow\n",
        "                    iC = col*stride + fillterCol\n",
        "                    in_val = input[i_batch, i_chanel,iR, iC]\n",
        "                    cuda.atomic.add(\n",
        "                        filter_gradient, (fillterIdx, i_chanel,fillterRow, fillterCol), input[i_batch, i_chanel,iR, iC] * out_value)\n",
        "                    if(not (in_val <= 0 and activation == 1)):\n",
        "                      cuda.atomic.add(input_gradient, (i_batch, i_chanel,iR, iC),\n",
        "                                          weights[fillterIdx,i_chanel, fillterRow, fillterCol] * out_value)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Convolution(Layer):\n",
        "    def __init__(self, n_filters=32, filter_size=3, stride=1, activation=None, input_shape=(28, 28, 1)):\n",
        "        self.input_shape = input_shape\n",
        "        self.n_filters = n_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.bias = np.zeros((n_filters, 1))\n",
        "        self.init_weight()\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_width = (self.input_shape[2] -\n",
        "                        self.filter_size) // self.stride + 1\n",
        "        output_height = (\n",
        "            self.input_shape[1] - self.filter_size) // self.stride + 1\n",
        "\n",
        "        return ( self.n_filters,output_height, output_width)\n",
        "\n",
        "\n",
        "    def init_weight(self):\n",
        "        self.weights = np.random.randn(\n",
        "            self.n_filters, self.input_shape[0],self.filter_size, self.filter_size)/(self.filter_size**2)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        self.inputs = inputs\n",
        "        n_batchs, n_chanels,in_height, in_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        output_height, output_width = self.get_out_shape()[1:]\n",
        "        block_size = (8, 8, 8)\n",
        "        grid_size = ((n_batchs-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        d_outputs = cuda.device_array((n_batchs, self.n_filters,output_height, output_width ))\n",
        "        self.d_weights = cuda.to_device(self.weights)\n",
        "        self.d_inputs = cuda.to_device(self.inputs)\n",
        "        conv_forward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, self.d_weights, 1, d_outputs, int(self.activation == \"relu\"))\n",
        "        outputs = d_outputs.copy_to_host()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        n_batchs,input_channels, input_height, input_width = self.inputs.shape\n",
        "        _,n_filters,  output_height, output_width = output_gradient.shape\n",
        "        block_size = (4, 4, 4)\n",
        "        grid_size = ((n_batchs-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        d_filter_grad = cuda.device_array(self.weights.shape)\n",
        "        d_input_grad = cuda.device_array(self.inputs.shape)\n",
        "        d_output_grad = cuda.to_device(output_gradient)\n",
        "        # call kernel\n",
        "        conv_backward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, self.d_weights, 1, d_input_grad, d_output_grad, d_filter_grad, int(self.activation == \"relu\"))\n",
        "        cuda.synchronize()\n",
        "        input_gradient = d_input_grad.copy_to_host()\n",
        "        filter_gradient = d_filter_grad.copy_to_host()\n",
        "        ## ===========END USING DEVICE===========##\n",
        "        self.weights -= learning_rate * filter_gradient/n_batchs\n",
        "\n",
        "        return input_gradient\n"
      ],
      "metadata": {
        "id": "iqfppCsjGXpO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Convolution\n",
        "```\n",
        "+Forward:\n",
        "Input: Input, weights, stride, activation\n",
        "  Cách cài đặt hàm kernel:\n",
        "  Chiều của output sẽ là ( n_batch, out_height, out_width, n_filter)\n",
        "  Mỗi thread sẽ phụ trách 1 phần tử output bao gồm n_batch, out_height, out_width.\n",
        "  Dùng block 3d và grid 3d, chọn chiều x ứng với n_batch, y ứng với out_height, z ứng với out_width\n",
        "Output: Ma trận kết quả “output”\n",
        "\n",
        "+Backward:\n",
        "Input: Input,output_grad, weight\n",
        "Cách cài đặt hàm kernel:\n",
        "  Chiều của output_grad là (n_batch, out_height, out_width, n_filter))\n",
        "  Mỗi thread sẽ phụ trách 1 phần tử trong output_grad bao gồm n_batch, out_height, out_width.\n",
        "  Dùng block 3d và grid 3d, chọn chiều x ứng với n_batch, y ứng với out_height, z ứng với out_width\n",
        "  Ngoài ra giữa các thread sẽ cộng dồn giá trị của Input_grad và weight_grad tại một thời điểm vì vậy cần sử dụng hàm atomic_add để cộng dồn giá trị của phần tử\n",
        "Output: Ma trận Input_grad, weight_grad\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "y4uUPWg1mG8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "5TwX1UPqGXpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(16,100,100)\n",
        "inputs = np.random.randint(0,255,(32,*input_shape))/255\n",
        "conv = Convolution(32,3,1,input_shape=input_shape)\n",
        "%time out_host=conv.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c540ad33-37c6-4c10-8ecd-00e8a2655150",
        "id": "Fh6lBE1-GXpP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 155 ms, sys: 24 ms, total: 179 ms\n",
            "Wall time: 178 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "T5RVz5xnGXpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=conv.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7ea508-b37d-4713-da9f-6375a1eccc44",
        "id": "kqTVa4T0GXpQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 762 ms, sys: 8.93 ms, total: 771 ms\n",
            "Wall time: 796 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Maxpooling Layer\n",
        "#------------MaxPool2D kernel--------------#\n",
        "@cuda.jit\n",
        "def maxPool2D_forward_kernel(inputs, outputs, stride, pool_size):\n",
        "    n_batchs,n_chanels, in_height, in_width = inputs.shape\n",
        "    n_batchs,n_chanels, output_height, output_width = outputs.shape\n",
        "    ibatch, out_h, out_w = cuda.grid(3)\n",
        "    # Max pool over input\n",
        "    if(ibatch >= n_batchs or out_h >= output_height or out_w >= output_width):\n",
        "        return\n",
        "\n",
        "    for i_chanel in range(n_chanels):\n",
        "        max_value = -np.inf\n",
        "        for h_pool in range(pool_size):\n",
        "            for w_pool in range(pool_size):\n",
        "                max_value = max(\n",
        "                    max_value, inputs[ibatch, i_chanel,out_h*stride+h_pool, w_pool+out_w*stride])\n",
        "        outputs[ibatch,i_chanel, out_h, out_w] = max_value\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def maxPool2D_backward_kernel(inputs, inputs_grad, outputs_grad, stride, pool_size):\n",
        "    n_batchs,n_chanels, in_height, in_width = inputs.shape\n",
        "    n_batchs,n_chanels, output_height, output_width,  = outputs_grad.shape\n",
        "    ibatch, out_h, out_w = cuda.grid(3)\n",
        "    # Max pool over input\n",
        "    if(ibatch >= n_batchs or out_h >= output_height or out_w >= output_width):\n",
        "        return\n",
        "    for i_chanel in range(n_chanels):\n",
        "        max_value = -np.inf\n",
        "        for h_pool in range(pool_size):\n",
        "            for w_pool in range(pool_size):\n",
        "                max_value = max(\n",
        "                    max_value, inputs[ibatch, i_chanel,out_h*stride+h_pool, w_pool+out_w*stride])\n",
        "\n",
        "        for h_pool in range(pool_size):\n",
        "            for w_pool in range(pool_size):\n",
        "                if(inputs[ibatch,i_chanel ,out_h*stride+h_pool, w_pool+out_w*stride] == max_value):\n",
        "                    inputs_grad[ibatch, i_chanel,out_h*stride+h_pool, w_pool+out_w*stride] += outputs_grad[ibatch,i_chanel,  out_h, out_w]\n",
        "\n",
        "\n",
        "class MaxPool2D(Layer):\n",
        "    def __init__(self, pool_size=2, stride=2, input_shape=(28, 28, 1)):\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.inputs_device = None\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_height = ( self.input_shape[1] - self.pool_size) // self.stride + 1\n",
        "        output_width = (self.input_shape[2] -  self.pool_size) // self.stride + 1\n",
        "        return (self.input_shape[0],output_height, output_width)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # Save input\n",
        "        batch_size,num_channels, input_height, input_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        self.inputs = inputs\n",
        "        ( _,output_height, output_width) = self.get_out_shape()\n",
        "        d_outputs = cuda.device_array(\n",
        "            (batch_size,num_channels, output_height, output_width))\n",
        "        block_size = (8, 4, 4)\n",
        "        grid_size = ((batch_size-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        self.d_inputs = cuda.to_device(inputs)\n",
        "        maxPool2D_forward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, d_outputs, self.stride, self.pool_size)\n",
        "        outputs = d_outputs.copy_to_host()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        batch_size,num_channels, output_height, output_width = output_gradient.shape\n",
        "        d_input_grad = cuda.device_array(self.inputs.shape)\n",
        "        d_output_grad = cuda.to_device(output_gradient)\n",
        "        block_size = (8, 4, 4)\n",
        "        grid_size = ((batch_size-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        maxPool2D_backward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, d_input_grad, d_output_grad, self.stride, self.pool_size)\n",
        "        input_gradient = d_input_grad.copy_to_host()\n",
        "        return input_gradient\n",
        "\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "q6iPsh1_GXpR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Convolution\n",
        "```\n",
        "+Forward:\n",
        "Input: Input, stride, pool size\n",
        "  Cách cài đặt hàm kernel:\n",
        "  Chiều của output sẽ là ( n_batch, out_height, out_width, n_chanel)\n",
        "  Mỗi thread sẽ phụ trách 1 phần tử output bao gồm n_batch, out_height, out_width.\n",
        "  Dùng block 3d và grid 3d, chọn chiều x ứng với n_batch, y ứng với out_height, z ứng với out_width\n",
        "Output: Ma trận kết quả “output”\n",
        "\n",
        "+Backward:\n",
        "Input: Input,output_grad, stride, pool_size\n",
        "  Cách cài đặt hàm kernel:\n",
        "  Chiều của output_grad là (n_batch, out_height, out_width, n_chanel)\n",
        "  Mỗi thread sẽ phụ trách 1 phần tử trong output_grad bao gồm n_batch, out_height, out_width.\n",
        "  Dùng block 3d và grid 3d, chọn chiều x ứng với n_batch, y ứng với out_height, z ứng với out_width\n",
        "Output: Input_grad\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "fSoc5oVGmX3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "dD_SLG9sGXpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(32,200,200)\n",
        "inputs = np.random.randint(0,255,(64,*input_shape))/255\n",
        "maxp = MaxPool2D(2,2,input_shape=input_shape)\n",
        "%time out_host=maxp.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec703243-cedb-4420-b49f-3e9d75324f48",
        "id": "Gm9ym3bNGXpR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 191 ms, sys: 34 ms, total: 225 ms\n",
            "Wall time: 223 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "jymcBSgUGXpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=maxp.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0136d3d-7a5f-49f3-a3a1-5b9881fcac50",
        "id": "G0I-PS8OGXpS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 215 ms, sys: 115 ms, total: 330 ms\n",
            "Wall time: 328 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Dense Layer\n",
        "\n",
        "@cuda.jit\n",
        "def dense_forward_kernel(inputs, weights, bias, outputs):\n",
        "    row, col = cuda.grid(2)\n",
        "    height = weights.shape[0]\n",
        "    if(row >= outputs.shape[0] or col >= outputs.shape[1]):\n",
        "        return\n",
        "    sum = 0\n",
        "    for i in range(inputs.shape[1]):\n",
        "        sum += inputs[row, i] * weights[i, col]\n",
        "    outputs[row, col] = sum + bias[0, col]\n",
        "\n",
        "\n",
        "\n",
        "class Dense(Layer):\n",
        "    def __init__(self, num_outputs, activation=None, input_shape=100):\n",
        "        self.num_outputs = num_outputs\n",
        "        self.biases = np.zeros((1, num_outputs))\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.input_shape = input_shape\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        self.weights = np.random.randn(\n",
        "            self.input_shape, self.num_outputs) / self.num_outputs\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        return self.num_outputs\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        assert self.input_shape == inputs.shape[-1], \"Input shape incorrect\"\n",
        "        block_size = (8, 4)\n",
        "        grid_size = ((inputs.shape[0]-1)//block_size[0]+1,\n",
        "                     (self.num_outputs-1)//block_size[1]+1)\n",
        "        # if(grid_size[0]*grid_size[1] < 128):\n",
        "        #     self.use_device = False\n",
        "        # outputs = None\n",
        "        # if(self.use_device == False):\n",
        "        #     outputs = np.dot(inputs, self.weights) + self.biases\n",
        "        # else:\n",
        "        self.d_weights = cuda.to_device(self.weights)\n",
        "        self.d_biases = cuda.to_device(self.biases)\n",
        "        d_outputs = cuda.device_array((inputs.shape[0], self.num_outputs))\n",
        "        self.d_inputs = cuda.to_device(inputs)\n",
        "        start = time.time()\n",
        "        dense_forward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, self.d_weights, self.d_biases, d_outputs)\n",
        "        outputs = d_outputs.copy_to_host()\n",
        "\n",
        "        # if(self.activation==\"relu\"):\n",
        "        #   outputs = np.maximum(0,outputs)\n",
        "        if self.activation == \"softmax\":\n",
        "            outputs = self.softmax(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x-np.max(x, axis=1, keepdims=True))\n",
        "        return e_x/e_x.sum(axis=1, keepdims=True)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        # start = time.time()\n",
        "        # input_grad=None\n",
        "        # if(self.use_device==False):\n",
        "\n",
        "        input_grad = np.dot(output_gradient, self.weights.T)\n",
        "        weights_gradient = np.dot(self.inputs.T, output_gradient)\n",
        "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.biases -= learning_rate * biases_gradient\n",
        "\n",
        "        return input_grad"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QUEuPcWsGXpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Convolution\n",
        "```\n",
        "+Forward:\n",
        "Input: Input, weigth, bias\n",
        "  Cách cài đặt hàm kernel:\n",
        "  Chiều của output sẽ là ( n_batch,   n_out)\n",
        "  Mỗi thread sẽ phụ trách 1 phần tử output bao gồm n_batch, n_out,\n",
        "  Dùng block 2d và grid 2d, chọn chiều x ứng với n_batch, y ứng với n_out,\n",
        "Output: Ma trận kết quả “output”\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "JWMfwaIPmn_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=np.random.randint(1,255, (256,10000))/255\n",
        "dense=Dense(1024, input_shape= 10000)\n",
        "%time out_host=dense.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694e153b-b907-4554-808a-9577568b4261",
        "id": "earYPbQUGXpT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 145 ms, sys: 0 ns, total: 145 ms\n",
            "Wall time: 145 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test"
      ],
      "metadata": {
        "id": "mFGH8FAJNXL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelIII=CNNModel([ \n",
        "    Convolution(n_filters=16, filter_size=3, stride=1,activation='relu',input_shape=(1,28,28)),\n",
        "    MaxPool2D(pool_size=2), \n",
        "    Convolution(n_filters=32, filter_size=3, stride=1,activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "R4j40AY4NJ7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "modelIII.fit(x_train,y_train, epochs=3, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJq007_aNnlP",
        "outputId": "657843bb-e629-4965-9914-a852a6dbc728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3:\n",
            " 469/469 [==============================] accuaray: 0.91726, train loss = 0.12463\n",
            "Epoch 2/3:\n",
            " 469/469 [==============================] accuaray: 0.96034, train loss = 0.05983\n",
            "Epoch 3/3:\n",
            " 469/469 [==============================] accuaray: 0.97228, train loss = 0.04016CPU times: user 1min 52s, sys: 1min 15s, total: 3min 8s\n",
            "Wall time: 2min 2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time y_predict =modelIII.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUcDUw3yvQtq",
        "outputId": "221debc2-cdf1-4c2c-e878-05cfa64d0586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.19 s, sys: 274 ms, total: 1.46 s\n",
            "Wall time: 1.46 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. PHIÊN BẢN SONG SONG V2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QCOTy97lN6HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân tích:\n",
        "```\n",
        "- Phiên bản song song đầu tiên chỉ đơn thuần là ánh xạ phiên bản tuần tự bằng cách sử dụng grid và thread thay thế các vòng lặp\n",
        "- Tuy nhiên ở phiên bản cải tiến lần này, bọn em sẽ tối ưu việc truy xuất vùng nhớ, hạn chế sử dụng GMEM bằng cách sử RMEM + SMEM giúp việc truy xuất dữ liệu trở nên nhanh chóng hơn.\n",
        "```"
      ],
      "metadata": {
        "id": "H1ycG-TPN6Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Convolution Layer\n",
        "import numpy as np\n",
        "from numba import cuda, types as numba_types\n",
        "\n",
        "#------------Convolution kernel--------------#\n",
        "@cuda.jit\n",
        "def conv_forward_kernel(d_inputs, weights, stride, outputs, activation):\n",
        "    shared_input = cuda.shared.array((8,6,6),numba_types.float32)\n",
        "    i_batch, row, col = cuda.grid(3)\n",
        "    n_batch, n_filters,output_height, output_width = outputs.shape\n",
        "    if( i_batch >= n_batch): return \n",
        "    filter_size= weights.shape[-1]\n",
        "    n_chanels=d_inputs.shape[1]\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    tz = cuda.threadIdx.z\n",
        "    by=cuda.blockIdx.y*cuda.blockDim.y\n",
        "    bz=cuda.blockIdx.z*cuda.blockDim.z\n",
        "    for fillterIdx in range(n_filters):\n",
        "        sum_val = 0\n",
        "        for chanel_idx in range(n_chanels):\n",
        "            for i in range(4):\n",
        "              idx=(ty*4+tz)+i*16\n",
        "              y,z=idx//6,idx%6\n",
        "              if(y>=6): break\n",
        "              shared_input[tx,y,z] =d_inputs[i_batch,chanel_idx,by+y, bz+z]\n",
        "            cuda.syncthreads()\n",
        "            for fillterRow in range(filter_size):\n",
        "                for fillterCol in range(filter_size):\n",
        "                    sum_val +=shared_input[tx,fillterRow+ty,fillterCol+tz]*weights[fillterIdx,chanel_idx, fillterRow, fillterCol]\n",
        "            cuda.syncthreads()\n",
        "                   \n",
        "        if not (row >= output_height or col >= output_width):\n",
        "          if(activation == 1 and sum_val < 0):\n",
        "              sum_val = 0\n",
        "          outputs[i_batch,fillterIdx, row, col] = sum_val\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def conv_backward_kernel(d_inputs, weights, stride, input_gradient, output_gradient, filter_gradient, activation):\n",
        "    shared_input = cuda.shared.array((8,6,6),numba_types.float32)\n",
        "    n_chanels,filter_size = weights.shape[1:-1]\n",
        "    n_batch,n_filters, output_height, output_width  = output_gradient.shape\n",
        "    i_batch, row, col = cuda.grid(3)\n",
        "    # if(row >= output_height or col >= output_width or i_batch >= n_batch):\n",
        "    #     return\n",
        "    if(i_batch >= n_batch): \n",
        "      return\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    tz = cuda.threadIdx.z\n",
        "    by=cuda.blockIdx.y*cuda.blockDim.y\n",
        "    bz=cuda.blockIdx.z*cuda.blockDim.z\n",
        "    for fillterIdx in range(n_filters):\n",
        "        out_value = output_gradient[i_batch, fillterIdx,row, col]\n",
        "        for i_chanel in range(n_chanels):\n",
        "          for i in range(3):\n",
        "              idx=(ty*4+tz)+i*16\n",
        "              y,z=idx//6,idx%6\n",
        "              if(y>=6): break\n",
        "              shared_input[tx,y,z] =d_inputs[i_batch,i_chanel,by+y, bz+z]\n",
        "          cuda.syncthreads()\n",
        "          if not (row >= output_height or col >= output_width):\n",
        "            for fillterRow in range(filter_size):\n",
        "                for fillterCol in range(filter_size):\n",
        "                        iR = row*stride + fillterRow\n",
        "                        iC = col*stride + fillterCol\n",
        "                        in_val = d_inputs[i_batch, i_chanel,iR, iC]\n",
        "                        cuda.atomic.add(\n",
        "                            filter_gradient, (fillterIdx, i_chanel,fillterRow, fillterCol), in_val* out_value)\n",
        "                        if(not (in_val <= 0 and activation == 1)):\n",
        "                          cuda.atomic.add(input_gradient, (i_batch, i_chanel,iR, iC),\n",
        "                                              weights[fillterIdx,i_chanel, fillterRow, fillterCol] * out_value)\n",
        "          cuda.syncthreads()\n",
        "\n",
        "\n",
        "class Convolution(Layer):\n",
        "    def __init__(self, n_filters=32, filter_size=3, stride=1, activation=None, input_shape=(28, 28, 1)):\n",
        "        self.input_shape = input_shape\n",
        "        self.n_filters = n_filters\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.bias = np.zeros((n_filters, 1))\n",
        "        self.init_weight()\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_width = (self.input_shape[2] -\n",
        "                        self.filter_size) // self.stride + 1\n",
        "        output_height = (\n",
        "            self.input_shape[1] - self.filter_size) // self.stride + 1\n",
        "\n",
        "        return ( self.n_filters,output_height, output_width)\n",
        "\n",
        "\n",
        "    def init_weight(self):\n",
        "        self.weights = np.random.randn(\n",
        "            self.n_filters, self.input_shape[0],self.filter_size, self.filter_size)/(self.filter_size**2)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        self.inputs = inputs\n",
        "        n_batchs, n_chanels,in_height, in_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        output_height, output_width = self.get_out_shape()[1:]\n",
        "        block_size = (8, 4, 4)\n",
        "        grid_size = ((n_batchs-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        d_outputs = cuda.device_array((n_batchs, self.n_filters,output_height, output_width ))\n",
        "        self.d_weights = cuda.to_device(self.weights)\n",
        "        self.d_inputs = cuda.to_device(self.inputs)\n",
        "        conv_forward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, self.d_weights, 1, d_outputs, int(self.activation == \"relu\"))\n",
        "        outputs = d_outputs.copy_to_host()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        n_batchs,input_channels, input_height, input_width = self.inputs.shape\n",
        "        _,n_filters,  output_height, output_width = output_gradient.shape\n",
        "        block_size = (8, 4, 4)\n",
        "        grid_size = ((n_batchs-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        d_filter_grad = cuda.device_array(self.weights.shape)\n",
        "        d_input_grad = cuda.device_array(self.inputs.shape)\n",
        "        d_output_grad = cuda.to_device(output_gradient)\n",
        "        # call kernel\n",
        "        conv_backward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, self.d_weights, 1, d_input_grad, d_output_grad, d_filter_grad, int(self.activation == \"relu\"))\n",
        "        cuda.synchronize()\n",
        "        input_gradient = d_input_grad.copy_to_host()\n",
        "        filter_gradient = d_filter_grad.copy_to_host()\n",
        "        ## ===========END USING DEVICE===========##\n",
        "        self.weights -= learning_rate * filter_gradient/n_batchs\n",
        "\n",
        "        return input_gradient\n"
      ],
      "metadata": {
        "id": "nUa3Kgo4N6Hg",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - Convolution\n",
        "```\n",
        "Các bước thiết kế tương tự như phiên bản song song v1\n",
        "Tuy nhiên ở đây sẽ sử dụng SMEM để lưu input trong cùng một block cho việc sử dụng lại nhiều lần\n",
        "Ngoài ra ở bản kernel backward bọn em có sử dụng RMEM để lữu trữ output_grad, giúp hạn chế việc truy xuất nhiều lần đến GMEM\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "QmVi4_gnok98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "YSGvUEPhN6Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(16,100,100)\n",
        "inputs = np.random.randint(0,255,(32,*input_shape))/255\n",
        "conv = Convolution(32,3,1,input_shape=input_shape)\n",
        "%time out_host=conv.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b355e68-4d49-45be-edf7-291e2870d9fb",
        "id": "CIeTXovdN6Hg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 114 ms, sys: 20 ms, total: 134 ms\n",
            "Wall time: 131 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "hI7Tz5dNN6Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=conv.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d68e9db-04ab-4bf8-a614-ac75b7292877",
        "id": "g3IkMlM-N6Hh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 331 ms, sys: 10.1 ms, total: 341 ms\n",
            "Wall time: 341 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Maxpooling Layer\n",
        "@cuda.jit\n",
        "def maxPool2D_forward_kernel(d_inputs, outputs, stride, pool_size):\n",
        "    share_size = 8\n",
        "    shared_input = cuda.shared.array((8,share_size,share_size),numba_types.float32)\n",
        "    n_batchs,n_chanels, in_height, in_width = d_inputs.shape\n",
        "    n_batchs,n_chanels, output_height, output_width = outputs.shape\n",
        "    i_batch, out_h, out_w = cuda.grid(3)\n",
        "    # Max pool over input\n",
        "    if(i_batch >= n_batchs): return\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    tz = cuda.threadIdx.z\n",
        "    by=cuda.blockIdx.y*cuda.blockDim.y * stride\n",
        "    bz=cuda.blockIdx.z*cuda.blockDim.z * stride\n",
        "\n",
        "    for i_chanel in range(n_chanels):\n",
        "        for i in range(4):\n",
        "          idx=(ty*4+tz)+i*16\n",
        "          y,z=idx//share_size,idx%share_size\n",
        "          if(y>=share_size): break\n",
        "          shared_input[tx,y,z] =d_inputs[i_batch,i_chanel,by+y, bz+z]\n",
        "        cuda.syncthreads()\n",
        "        max_value = -np.inf\n",
        "        if not (out_h >= output_height or out_w >= output_width):\n",
        "          for h_pool in range(pool_size):\n",
        "              for w_pool in range(pool_size):\n",
        "                  max_value = max(\n",
        "                      # max_value, d_inputs[i_batch, i_chanel,out_h*stride+h_pool, w_pool+out_w*stride])\n",
        "                      max_value, shared_input[tx,ty*stride+h_pool, w_pool+tz*stride])\n",
        "          outputs[i_batch,i_chanel, out_h, out_w] = max_value\n",
        "        cuda.syncthreads()\n",
        "\n",
        "@cuda.jit\n",
        "def maxPool2D_backward_kernel(d_inputs, inputs_grad, outputs_grad, stride, pool_size):\n",
        "    share_size = 8\n",
        "    shared_input = cuda.shared.array((8,share_size,share_size),numba_types.float32)\n",
        "    n_batchs,n_chanels, in_height, in_width = d_inputs.shape\n",
        "    n_batchs,n_chanels, output_height, output_width,  = outputs_grad.shape\n",
        "    i_batch, out_h, out_w = cuda.grid(3)\n",
        "    # Max pool over input\n",
        "    if(i_batch >= n_batchs ):\n",
        "        return\n",
        "    tx = cuda.threadIdx.x\n",
        "    ty = cuda.threadIdx.y\n",
        "    tz = cuda.threadIdx.z\n",
        "    by=cuda.blockIdx.y*cuda.blockDim.y * stride\n",
        "    bz=cuda.blockIdx.z*cuda.blockDim.z * stride\n",
        "    for i_chanel in range(n_chanels):\n",
        "        for i in range(4):\n",
        "          idx=(ty*4+tz)+i*16\n",
        "          y,z=idx//share_size,idx%share_size\n",
        "          if(y>=share_size): break\n",
        "          shared_input[tx,y,z] =d_inputs[i_batch,i_chanel,by+y, bz+z]\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        max_value = -np.inf\n",
        "        if not (out_h >= output_height or out_w >= output_width):\n",
        "          for h_pool in range(pool_size):\n",
        "              for w_pool in range(pool_size):\n",
        "                  max_value = max( max_value,  shared_input[tx,ty*stride+h_pool, w_pool+tz*stride])\n",
        "          \n",
        "          for h_pool in range(pool_size):\n",
        "              for w_pool in range(pool_size):\n",
        "                  if( shared_input[tx,ty*stride+h_pool, w_pool+tz*stride] ==max_value):\n",
        "                      inputs_grad[i_batch, i_chanel,out_h*stride+h_pool, w_pool+out_w*stride] += outputs_grad[i_batch,i_chanel,  out_h, out_w]\n",
        "        cuda.syncthreads()\n",
        "#------------Linear kernel--------------#\n",
        "\n",
        "class MaxPool2D(Layer):\n",
        "    def __init__(self, pool_size=2, stride=2, input_shape=(28, 28, 1)):\n",
        "        self.pool_size = pool_size\n",
        "        self.stride = stride\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.inputs_device = None\n",
        "        self.input_shape = input_shape\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        output_height = ( self.input_shape[1] - self.pool_size) // self.stride + 1\n",
        "        output_width = (self.input_shape[2] -  self.pool_size) // self.stride + 1\n",
        "        return (self.input_shape[0],output_height, output_width)\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # Save input\n",
        "        batch_size,num_channels, input_height, input_width = inputs.shape\n",
        "        assert self.input_shape == inputs.shape[1:], \"Input shape incorrect\"\n",
        "        self.inputs = inputs\n",
        "        ( _,output_height, output_width) = self.get_out_shape()\n",
        "        d_outputs = cuda.device_array(\n",
        "            (batch_size,num_channels, output_height, output_width))\n",
        "        block_size = (8, 4, 4)\n",
        "        grid_size = ((batch_size-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        self.d_inputs = cuda.to_device(inputs)\n",
        "        maxPool2D_forward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, d_outputs, self.stride, self.pool_size)\n",
        "        outputs = d_outputs.copy_to_host()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        batch_size,num_channels, output_height, output_width = output_gradient.shape\n",
        "        d_input_grad = cuda.device_array(self.inputs.shape)\n",
        "        d_output_grad = cuda.to_device(output_gradient)\n",
        "        block_size = (8, 4, 4)\n",
        "        grid_size = ((batch_size-1)//block_size[0]+1, (output_height-1) //\n",
        "                      block_size[1]+1, (output_width-1)//block_size[2]+1)\n",
        "        maxPool2D_backward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, d_input_grad, d_output_grad, self.stride, self.pool_size)\n",
        "        input_gradient = d_input_grad.copy_to_host()\n",
        "        return input_gradient\n",
        "\n",
        "\n",
        "    def init_weight(self):\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "XIvKSzNMN6Hh",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thiết kế - MaxPooling\n",
        "```\n",
        "Cơ chế thuật toán MaxPooling cũng gần tương tự với Lớp Convolution CNN\n",
        "nên việc thiết kế sử dụng smem,rmem cũng tương tự với lớp Convolution.\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "uATv-h9kp5M2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Forward Test"
      ],
      "metadata": {
        "id": "h54KqhhLN6Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(32,200,200)\n",
        "inputs = np.random.randint(0,255,(64,*input_shape))/255\n",
        "maxp = MaxPool2D(2,2,input_shape=input_shape)\n",
        "%time out_host=maxp.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab95ea6-424c-4e6b-dbe4-c80190bce496",
        "id": "CIyYZuplN6Hh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 188 ms, sys: 34 ms, total: 222 ms\n",
            "Wall time: 217 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Backward Test"
      ],
      "metadata": {
        "id": "7ih0lIT8N6Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time in_grad_host=maxp.backward(out_host,0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d839c9-269d-4f1c-d25a-d3ace8e229fd",
        "id": "yhK8ULkhN6Hh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 181 ms, sys: 119 ms, total: 300 ms\n",
            "Wall time: 300 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Dense Layer\n",
        "\n",
        "@cuda.jit\n",
        "def dense_forward_kernel(inputs, weights, bias, outputs):\n",
        "    row, col = cuda.grid(2)\n",
        "    height = weights.shape[0]\n",
        "    if(row >= outputs.shape[0] or col >= outputs.shape[1]):\n",
        "        return\n",
        "    sum = 0\n",
        "    for i in range(inputs.shape[1]):\n",
        "        sum += inputs[row, i] * weights[i, col]\n",
        "    outputs[row, col] = sum + bias[0, col]\n",
        "\n",
        "\n",
        "\n",
        "class Dense(Layer):\n",
        "    def __init__(self, num_outputs, activation=None, input_shape=100):\n",
        "        self.num_outputs = num_outputs\n",
        "        self.biases = np.zeros((1, num_outputs))\n",
        "        self.activation = activation\n",
        "        self.use_device = False\n",
        "        self.inputs = None\n",
        "        self.input_shape = input_shape\n",
        "        self.init_weight()\n",
        "\n",
        "    def init_weight(self):\n",
        "        self.weights = np.random.randn(\n",
        "            self.input_shape, self.num_outputs) / self.num_outputs\n",
        "\n",
        "    def get_out_shape(self):\n",
        "        return self.num_outputs\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        assert self.input_shape == inputs.shape[-1], \"Input shape incorrect\"\n",
        "        block_size = (8, 4)\n",
        "        grid_size = ((inputs.shape[0]-1)//block_size[0]+1,\n",
        "                     (self.num_outputs-1)//block_size[1]+1)\n",
        "        # if(grid_size[0]*grid_size[1] < 128):\n",
        "        #     self.use_device = False\n",
        "        # outputs = None\n",
        "        # if(self.use_device == False):\n",
        "        #     outputs = np.dot(inputs, self.weights) + self.biases\n",
        "        # else:\n",
        "        self.d_weights = cuda.to_device(self.weights)\n",
        "        self.d_biases = cuda.to_device(self.biases)\n",
        "        d_outputs = cuda.device_array((inputs.shape[0], self.num_outputs))\n",
        "        self.d_inputs = cuda.to_device(inputs)\n",
        "        start = time.time()\n",
        "        dense_forward_kernel[grid_size, block_size](\n",
        "            self.d_inputs, self.d_weights, self.d_biases, d_outputs)\n",
        "        outputs = d_outputs.copy_to_host()\n",
        "\n",
        "        # if(self.activation==\"relu\"):\n",
        "        #   outputs = np.maximum(0,outputs)\n",
        "        if self.activation == \"softmax\":\n",
        "            outputs = self.softmax(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x-np.max(x, axis=1, keepdims=True))\n",
        "        return e_x/e_x.sum(axis=1, keepdims=True)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        # start = time.time()\n",
        "        # input_grad=None\n",
        "        # if(self.use_device==False):\n",
        "\n",
        "        input_grad = np.dot(output_gradient, self.weights.T)\n",
        "        weights_gradient = np.dot(self.inputs.T, output_gradient)\n",
        "        biases_gradient = np.sum(output_gradient, axis=0, keepdims=True)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.biases -= learning_rate * biases_gradient\n",
        "\n",
        "        return input_grad"
      ],
      "metadata": {
        "id": "QwLqmAfeN6Hh",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=np.random.randint(1,255, (256,10000))/255\n",
        "dense=Dense(1024, input_shape= 10000)\n",
        "%time out_host=dense.forward(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694e153b-b907-4554-808a-9577568b4261",
        "id": "KcRu0NBTN6Hi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 145 ms, sys: 0 ns, total: 145 ms\n",
            "Wall time: 145 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test"
      ],
      "metadata": {
        "id": "yu_-ftS0N6Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelIV=CNNModel([ \n",
        "    Convolution(n_filters=16, filter_size=3, stride=1,activation='relu',input_shape=(1,28,28)),\n",
        "    MaxPool2D(pool_size=2), \n",
        "    Convolution(n_filters=32, filter_size=3, stride=1,activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "MTxnIbXNN6Hi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "modelIV.fit(x_train,y_train, epochs=3, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc26475-4b99-47c3-c142-fcd889493d3c",
        "id": "0WbhkSTrN6Hi"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3:\n",
            " 469/469 [==============================] accuaray: 0.89651, train loss = 0.15578\n",
            "Epoch 2/3:\n",
            " 469/469 [==============================] accuaray: 0.95984, train loss = 0.05976\n",
            "Epoch 3/3:\n",
            " 469/469 [==============================] accuaray: 0.97178, train loss = 0.04059CPU times: user 1min 40s, sys: 1min 7s, total: 2min 47s\n",
            "Wall time: 1min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%time y_predict =modelIV.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8XtPoANv47E",
        "outputId": "00f45fb7-6a39-48c2-93c9-67033b9d5c54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 957 ms, sys: 269 ms, total: 1.23 s\n",
            "Wall time: 1.28 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V. ĐÁNH GIÁ"
      ],
      "metadata": {
        "id": "RYqhW7eQpfOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Kịch bản đánh giá\n",
        "```\n",
        "- Để tiến hành kiểm thử mô hình CNN chạy trên host và device, chúng em sử dụng bộ dữ liệu Mnist gồm 60000 tập huấn luyện vè 10000 tập test\n",
        "- Huần luyện trên 3epoch và batch size là 128. \n",
        "- Model được xây dựng như sau:\n",
        "    Convolution(n_filters=16, filter_size=3, stride=1,activation='relu',input_shape=(1,28,28)),\n",
        "    MaxPool2D(pool_size=2), \n",
        "    Convolution(n_filters=32, filter_size=3, stride=1,activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128),\n",
        "    Dense(10, activation='softmax')\n",
        "- Kết quả huấn luyện cho thấy độ chính xác của mô hình tương đối tốt (>95% sau 3 epoch) \n",
        "```"
      ],
      "metadata": {
        "id": "B4spivXZ9k2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kết quả\n",
        "\n",
        "Bảng so sách thời gian chạy giữa các phiên bản cài đặt tuần tự và song song\n",
        "\n",
        "|           |host v1|host v2|Device v1|Device v2|\n",
        "|-----------|:-----:|:-----:|:-------:|:-------:|\n",
        "|Convolution|3m46   | 36.9s |   974ms |  472ms  |         \n",
        "|MaxPooling |19s    | 9s    |   551ms |  517ms  |         \n",
        "|Dense      |292ms  | 292ms |  289ms  |  289ms  |         \n",
        "|Training   | inf   |64m17s |   2m2   |  1m36   |        \n",
        "|Testing    |17m34  |1m32   | 1.46s    | 1.28s  |   "
      ],
      "metadata": {
        "id": "do3TZThgW2PC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nhận xét\n",
        "```\n",
        "- Ở phiên bản cài đặt tuần tự trên python, tốc độ tính toán rất chậm, đặc biệt là bước tính toán backward (tuần tự v1)\n",
        "- Tốc độ được bản tuần tự v1 được cái thiện hơn khi sử dụng thư viện tính toán numpy (tuần tự v2)\n",
        "- Sau khi cài đặt phiên bản song song trên cuda cho kết quả tốt hơn rất nhiều so với phiên bản tự trước đó (song song v1)\n",
        "- Việc sử dụng hiểu quả memory như SMEM, RMEM góp phần rút ngắn tốc độ truy xuất bộ nhớ tối ưu thời gian (song song v2)\n",
        "- Nhìn chung trong  3 lớp thời gian thực thực thì của Convolution là lớn nhất, sau đó là Maxpooling và cuối cùng là Dense (chiếm thời gian gần như không đáng kể)\n",
        "=> Đối với bài toán CNN nhận dạng hình ảnh, việc sử dụng GPU để xử lý song song là việc hết sức cần thiết và đặc biệt quan trọng giúp cho quá trình huấn luyện, nghiên cứu diễn ra nhanh và dễ dàng hơn.\n",
        "```"
      ],
      "metadata": {
        "id": "iPrs9obvdOH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VI. NHÌN LẠI QUÁ TRÌNH LÀM ĐỒ ÁN"
      ],
      "metadata": {
        "id": "MBk05wZ4LRyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kết quả đạt được\n",
        "- Học cách song song hóa một chương trình bằng cuda\n",
        "- Xây dựng mô hình CNN đơn giản có thể nhận diện được\n",
        "- Tăng tốc độ huấn luyện và dự đoán mô hình bằng cách sử dụng CUDA Numba, giúp cải thiện trải nghiệm người dùng và giảm thời gian xử lý.\n",
        "- Đạt được hiệu suất tốt trong việc phân loại ảnh với mô hình CNN. Mô hình có khả năng nhận dạng và phân loại đúng các đối tượng trong ảnh với độ chính xác cao."
      ],
      "metadata": {
        "id": "1dqCqLtwLd0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Khó khăn gặp phải\n",
        "- Việc xây dựng thuật toán khá phức tạp, tốn nhiều thời gian nghiên cứu"
      ],
      "metadata": {
        "id": "q3aXgz0IMfge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Định hướng tương lai\n",
        "- Nâng cao mô hình và tăng khả năng phân loại\n",
        "- Khám phá các kỹ thuật tối ưu hóa GPU khác"
      ],
      "metadata": {
        "id": "DeoxGgGlOG81"
      }
    }
  ]
}